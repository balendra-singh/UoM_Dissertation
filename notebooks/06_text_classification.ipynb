{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cx_DTX8L9ksf"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "\n",
        "drive_path = \"/content/drive/MyDrive/Dissertation/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Myfmu-tm5l-m"
      },
      "outputs": [],
      "source": [
        "!pip install datasets transformers sentencepiece\n",
        "!pip install transformers[torch]\n",
        "#!pip install sacremoses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TiTg_2-F5oWW"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "\n",
        "print(transformers.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ub-MqxB9-ZR"
      },
      "outputs": [],
      "source": [
        "# Define the list of labels\n",
        "labels = [\"Chat\", \"Contacts\", \"Aggregation\", \"Accessibility\", \"Consistency\",  \"Authentication\" ]\n",
        "\n",
        "# Create label2id dictionary\n",
        "label2id = {label: idx for idx, label in enumerate(labels)}\n",
        "\n",
        "# Create id2label dictionary\n",
        "id2label = {idx: label for label, idx in label2id.items()}\n",
        "\n",
        "print(\"label2id:\", label2id)\n",
        "print(\"id2label:\", id2label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_VLlSGv9YAo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(drive_path + 'ibm_labelled_user_stories.csv')\n",
        "\n",
        "# Map the labels to their corresponding IDs\n",
        "df['label'] = df['label'].map(label2id)\n",
        "df['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install contractions"
      ],
      "metadata": {
        "id": "rmWgyMbOJrEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import library\n",
        "import contractions\n",
        "\n",
        "def expand_contractions(text):\n",
        "  # creating an empty list\n",
        "  expanded_words = []\n",
        "  for word in text.split():\n",
        "    # using contractions.fix to expand the shortened words\n",
        "    expanded_words.append(contractions.fix(word))\n",
        "\n",
        "  expanded_text = ' '.join(expanded_words)\n",
        "  return expanded_text\n",
        "\n",
        "df['text'] = df['text'].apply(expand_contractions)"
      ],
      "metadata": {
        "id": "pWxr2yCAJCRo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string as string\n",
        "import re\n",
        "df['text'] = df['text'].apply(lambda x: re.sub('[%s]' % re.escape(string.punctuation), '' , x))\n",
        "df['text'] = df['text'].apply(lambda x: re.sub('W*dw*','',x))"
      ],
      "metadata": {
        "id": "NijBY4AaLS54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#remove stopwords\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stop_words.add('subject')\n",
        "stop_words.add('http')\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    return \" \".join([word for word in str(text).split() if word not in stop_words])\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: remove_stopwords(x))"
      ],
      "metadata": {
        "id": "iTfOaRPoLmeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace email addresses\n",
        "df['text'] = df['text'].apply(lambda x: re.sub(r'\\b[\\w.-]+?@\\w+?\\.\\w{2,4}\\b', 'emailadd', x))\n",
        "\n",
        "# Replace URLs\n",
        "df['text'] = df['text'].apply(lambda x: re.sub(r'(http[s]?://\\S+)|(\\w+\\.[A-Za-z]{2,4}\\S*)', 'urladd', x))"
      ],
      "metadata": {
        "id": "BNxilr0ML14Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "def lemmatize_words(text):\n",
        "    return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n",
        "df[\"text\"] = df[\"text\"].apply(lambda text: lemmatize_words(text))"
      ],
      "metadata": {
        "id": "mfY2nAiXMb32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"text\"] = df[\"text\"].apply(lambda text: re.sub(' +', ' ', text))"
      ],
      "metadata": {
        "id": "7s49RI2fMmho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fLr-2_hlM8JL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "He9VFs6o5Qc5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import Dataset, DatasetDict\n",
        "\n",
        "# Assuming df is your DataFrame with columns ['sentence', 'label', 'idx']\n",
        "\n",
        "# Splitting the data\n",
        "train_df, temp_df = train_test_split(df, test_size=0.3, stratify=df['label'], random_state=42)\n",
        "test_df, eval_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['label'], random_state=42)\n",
        "\n",
        "# Convert DataFrames to Dataset format\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)\n",
        "eval_dataset = Dataset.from_pandas(eval_df)\n",
        "\n",
        "# Create DatasetDict\n",
        "user_story_dataset = DatasetDict({\n",
        "    'train': train_dataset,\n",
        "    'validation': eval_dataset,\n",
        "    'test': test_dataset\n",
        "})\n",
        "\n",
        "user_story_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SELECT Model"
      ],
      "metadata": {
        "id": "3UnMZcWcd4Ou"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tN1Gdbmb-LSV"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_checkpoint = drive_path + 'BERT4RE/'\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenizer.add_special_tokens({'pad_token': '[PAD]'})"
      ],
      "metadata": {
        "id": "bxXTH6Dm8Cfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KRod2Rxv-S6p"
      },
      "outputs": [],
      "source": [
        "tokenizer.vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yqnb3Iuh-VhK"
      },
      "outputs": [],
      "source": [
        "tokenizer.special_tokens_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-jOAsj9x-XUM"
      },
      "outputs": [],
      "source": [
        "def tokenize_text(user_stories):\n",
        "    return tokenizer(user_stories[\"text\"], truncation=True,padding='max_length', max_length=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oqNwR8ia-n1D"
      },
      "outputs": [],
      "source": [
        "tokenized_dataset = user_story_dataset.map(tokenize_text, batched=True)\n",
        "tokenized_dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n",
        "\n",
        "y = train_df['label']\n",
        "classes = np.unique(y)\n",
        "weights = compute_class_weight('balanced', classes=classes, y=y)\n",
        "class_weights = {k: v for k, v in zip(classes, weights)}\n",
        "\n",
        "# Replace the keys\n",
        "new_class_weights = {id2label[key]: value for key, value in class_weights.items()}\n",
        "\n",
        "print(\"Class Weights:\", new_class_weights)"
      ],
      "metadata": {
        "id": "AGwkVh9dAMmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "class_weights_tensor = torch.tensor(weights, dtype=torch.float)"
      ],
      "metadata": {
        "id": "9EmQ-V5bNTr0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from transformers import Trainer\n",
        "\n",
        "\n",
        "class CustomTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        labels = inputs.pop(\"labels\")\n",
        "        # forward pass\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.get(\"logits\")\n",
        "\n",
        "        # Move class_weights_tensor to the model's device\n",
        "        class_weights_tensor = torch.tensor(weights, dtype=torch.float).to(model.device)\n",
        "\n",
        "        # compute custom loss\n",
        "        loss_fct = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
        "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
        "        return (loss, outputs) if return_outputs else loss"
      ],
      "metadata": {
        "id": "tDrDqXuXOAnc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-syvwOcexRe"
      },
      "outputs": [],
      "source": [
        "# from transformers import DataCollatorWithPadding\n",
        "# data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2bQRAZS9-2JF"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoConfig,DistilBertConfig,TFDistilBertModel\n",
        "\n",
        "num_labels = 6\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels, label2id=label2id, id2label=id2label,ignore_mismatched_sizes=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "from transformers import EarlyStoppingCallback, IntervalStrategy\n",
        "\n",
        "\n",
        "model_name = model_checkpoint.split(\"/\")[-1]\n",
        "batch_size = 16\n",
        "num_train_epochs = 50\n",
        "logging_steps = len(tokenized_dataset[\"train\"]) // (batch_size * num_train_epochs)\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir=f\"{model_name}-finetuned-user-story\",\n",
        "    evaluation_strategy= IntervalStrategy.STEPS, #\"epoch\"\n",
        "    #save_strategy='steps' #\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    eval_steps = 50,\n",
        "    learning_rate=2e-05,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=num_train_epochs,\n",
        "\n",
        "    #weight_decay=0.01,\n",
        "    logging_steps=logging_steps,\n",
        "    metric_for_best_model=\"f1\",\n",
        "    save_total_limit=5,\n",
        ")"
      ],
      "metadata": {
        "id": "VhFgcpdqQGt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7ksnQ6g_UCF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score,precision_score\n",
        "from datasets import load_metric\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "  predictions, labels = eval_pred\n",
        "  predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "  acc = accuracy_score(labels, predictions)\n",
        "  f1_macro = f1_score(labels, predictions, average='macro')\n",
        "\n",
        "  return {\n",
        "      \"Accuracy\": acc,\n",
        "      \"f1\": f1_macro,\n",
        "  }\n",
        "\n",
        "\n",
        "def compute_all_metrics(p):\n",
        "  pred, labels = p\n",
        "  pred = np.argmax(pred, axis=1)\n",
        "  accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
        "  recall = recall_score(y_true=labels, y_pred=pred,average='macro')\n",
        "  precision = precision_score(y_true=labels, y_pred=pred,average='macro')\n",
        "  f1 = f1_score(y_true=labels, y_pred=pred,average='macro')\n",
        "\n",
        "  return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01pWTu2CzxJZ"
      },
      "outputs": [],
      "source": [
        "CUDA_LAUNCH_BLOCKING=1\n",
        "TORCH_USE_CUDA_DSA=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZvOesglj0bnP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "os.environ['TORCH_USE_CUDA_DSA'] = \"1\""
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IRL140uBQ4Su"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Prfc2j5_r1T"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = CustomTrainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_all_metrics,\n",
        "    callbacks = [EarlyStoppingCallback(early_stopping_patience=3)]\n",
        "\n",
        "    #data_collator=data_collator\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHiX4dOx_uUg"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0QKs6_7__-P"
      },
      "outputs": [],
      "source": [
        "validation_results = trainer.evaluate(eval_dataset=tokenized_dataset[\"test\"])\n",
        "print(validation_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7k8ge1L1IrJk"
      },
      "source": [
        "## Hyperparameter search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNfajuw_IrJl"
      },
      "source": [
        "The `Trainer` supports hyperparameter search using [optuna](https://optuna.org/) or [Ray Tune](https://docs.ray.io/en/latest/tune/). For this last section you will need either of those libraries installed, just uncomment the line you want on the next cell and run it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YUdakNBhIrJl"
      },
      "outputs": [],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttfT0CqaIrJm"
      },
      "source": [
        "During hyperparameter search, the `Trainer` will run several trainings, so it needs to have the model defined via a function (so it can be reinitialized at each new run) instead of just having it passed. We jsut use the same function as before:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8sgjdLKcIrJm"
      },
      "outputs": [],
      "source": [
        "def model_init():\n",
        "    return AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels, label2id=label2id, id2label=id2label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMXfVJO4IrJo"
      },
      "source": [
        "And we can instantiate our `Trainer` like before:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71pt6N0eIrJo"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model_init=model_init,\n",
        "    args=args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset['validation'],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQxrzFP4IrJq"
      },
      "source": [
        "The method we call this time is `hyperparameter_search`. Note that it can take a long time to run on the full dataset for some of the tasks. You can try to find some good hyperparameter on a portion of the training dataset by replacing the `train_dataset` line above by:\n",
        "```python\n",
        "train_dataset = encoded_dataset[\"train\"].shard(index=1, num_shards=10)\n",
        "```\n",
        "for 1/10th of the dataset. Then you can run a full training on the best hyperparameters picked by the search."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5CWZ6HZfgrls"
      },
      "outputs": [],
      "source": [
        "def optuna_hp_space(trial):\n",
        "    return {\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-6, 1e-4, log=True),\n",
        "        \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [16, 32, 64, 128]),\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NboJ7kDOIrJq"
      },
      "outputs": [],
      "source": [
        "# best_run = trainer.hyperparameter_search(n_trials=5, direction=\"maximize\")\n",
        "best_trial = trainer.hyperparameter_search(\n",
        "    direction=\"maximize\",\n",
        "    backend=\"optuna\",\n",
        "    hp_space=optuna_hp_space,\n",
        "    n_trials=9,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUTD72qCIrJs"
      },
      "source": [
        "The `hyperparameter_search` method returns a `BestRun` objects, which contains the value of the objective maximized (by default the sum of all metrics) and the hyperparameters it used for that run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Psi4JymeIrJs"
      },
      "outputs": [],
      "source": [
        "#best_run\n",
        "best_trial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFdjWbRIIrJu"
      },
      "source": [
        "You can customize the objective to maximize by passing along a `compute_objective` function to the `hyperparameter_search` method, and you can customize the search space by passing a `hp_space` argument to `hyperparameter_search`. See this [forum post](https://discuss.huggingface.co/t/using-hyperparameter-search-in-trainer/785/10) for some examples.\n",
        "\n",
        "To reproduce the best training, just set the hyperparameters in your `TrainingArgument` before creating a `Trainer`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jThKEN97iuu7"
      },
      "outputs": [],
      "source": [
        "for n, v in best_trial.hyperparameters.items():\n",
        "  setattr(trainer.args, n, v)\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mjn2krYwrcp2"
      },
      "outputs": [],
      "source": [
        "validation_results = trainer.evaluate()\n",
        "print(validation_results)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}